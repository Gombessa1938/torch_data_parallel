# torch_DistributedDataParallel_test
learning pytorch distributed dataparallel <br>
https://pytorch.org/tutorials/beginner/dist_overview.html<br>
https://towardsdatascience.com/how-to-scale-training-on-multiple-gpus-dae1041f49d2<br>
